= Structured logging with SLF4J and Logback
:published_at: 2017-12-01
:hp-tags: java
:hp-image: /images/logos/slf4j.png

I stumbled upon the term "structured logging" reading https://kartar.net/2015/12/structured-logging/[a 2015 blog post by James Turnbull].
It's not a new concept. 
I discovered Python developpers had a library dedicated to *structured logging*: http://www.structlog.org[structlog].

In this article I will describe what can be done in Java with usual logging libraries like SLF4J et Logback.

== Structured logging with SLF4J

All Java developpers know how to log a message:
[source,java]
----
Logger demoLogger = LoggerFactory.getLogger("logodissey.DemoLogger");
demoLogger.info("Hello world!");
----

Properly configured, it produces a log like
[source]
----
21:10:29.178 [Thread-1] INFO  logodissey.DemoLogger - Hello world!
----
Notice, this "Hello world!" message is qualified with several fields:

* Timestamp
* Thread Id
* Level
* Logger/Category

We can add more contextual information to this list, and give more detail about what was going on when this log was printed. For instance, to log the user Id, let's use the MDC (Mapped Diagnostic Context):
[source,java]
----
MDC.put("userId", "gquintana");
demoLogger.info("Hello world!");
MDC.remove("userId");
----
The MDC is a map-like object filled in the Java code and used in the backend logging library to output custom data.
With the adequate configuration, we can get the user Id the log:
[source]
----
21:10:29.178 [Thread-1] gquintana INFO  logodissey.DemoLogger - Hello world!
----
The MDC can store any information about the user (user Id, session Id, token Id), about the current request (request Id, transaction Id), about long running threads (batch instance Id, broker client Id). 
Later on, this information will be part of the log.

Having this kind of information allows to group logs by user, by request, by processing.
Remember that logs may be scattered across differents servers, on different time periods. 
In short it allows to correlate logs belonging to the same scenario and find answers to questions like "what was the user X doing when he met this nasty error?"

Let's get back to the example, we saw the MDC stores extra information about logs.
The MDC is usually based on a thread local variable, this has two drawbacks:

1. It must be properly cleaned after being used, or you may experience information leaks if the thread is reused. Think about thread pools in web servers like Tomcat.
2. The information may no be properly transfered from one thread to another. Think about asynchronous calls.

As a result, calling `MDC.remove`, like the above example, (or `MDC.clear`) is required to clean the MDC after usage.
To avoid forgetting to do housekeeping afterwards, we can use a try-with-resource construct:
[source,java]
----
try(MDC.MDCCloseable mdc = MDC.putCloseable("user", "gquintana")) {
	demoLogger.info("Hello world!");
}
----
Hopefully, this kind of code won't make its way in your business code because it is usually hidden in an interceptor like a Servlet filter, a Spring aspect or a JAXRS interceptor. In Logback, there is a `MDCInsertingServletFilter` class which can be used as an example.


== JSON logging with Logback

At this point, a log is more than simple string, 
it is qualified with useful information: timestamp, level, thread, user, message.
In order to send it to a log collection tool like Elasticsearch, 
you should keep it in a structured format like JSON.
You should not flatten it in your own specific text format.

A structured format also has the virtue of handling properly multiline logs like stack traces, call traces or messages containing line separators (wanted or not).

Most popular log collection tools likes Filebeat, Graylog, Fluentd already uses some kind of compressed JSON format under the hood.
You should too.

Generating JSON logs with Logback is very easy. 
I'll show how to use two Logback extensions, 
the https://github.com/logstash/logstash-logback-encoder[Logstash Logback encoder] 
and the https://github.com/qos-ch/logback-contrib/wiki[Logback Contrib] library.

The first one uses a Logback extension point known as *encoder* that you can plug into any appender:
[source,xml]
----
    <appender name="FILE" class="ch.qos.logback.core.FileAppender">
        <file>log/log-odissey.log</file>
        <encoder class="net.logstash.logback.encoder.LogstashEncoder">
            <customFields>{"application":"log-odissey"}</customFields>
        </encoder>
    </appender>
----
It will produce the expected result:
[source,json]
----
{
  "@timestamp": "2017-11-25T21:10:29.178+01:00",
  "@version": 1,
  "message": "Hello world!",
  "logger_name": "logodissey.DemoLogger",
  "thread_name": "Thread-1",
  "level": "INFO",
  "level_value": 20000,
  "HOSTNAME": "my-laptop",
  "userId": "gquintana",
  "application": "log-odyssey"
}
----
The Maven coordinates for this library are `net.logstash.logback:logstash-logback-encoder:4.11`.

The second one uses a different extension point called *layout*.
In the end, it looks very similar to the first one, a bit more verbose though:
[source,xml]
----
    <appender name="FILE
    "class="ch.qos.logback.core.FileAppender">
        <file>target/log/log-odissey.log</file>
        <encoder class="ch.qos.logback.core.encoder.LayoutWrappingEncoder">
            <layout class="ch.qos.logback.contrib.json.classic.JsonLayout">
                <jsonFormatter class="ch.qos.logback.contrib.jackson.JacksonJsonFormatter"/>
                <appendLineSeparator>true</appendLineSeparator>
            </layout>
        </encoder>
    </appender>
----
The result is very close as well, but fields are named differently:
[source,json]
----
{
   "timestamp":"1511814391083",
   "level":"INFO",
   "thread":"Thread-1",
   "mdc":{"user":"gquintana"},
   "logger":"logodissey.DemoLogger",
   "message":"Hello world!",
   "context":"default"
}
----
In order to be on par with the first example, it is possible to subclass the `JsonLayout` and add custom fields:
[source,java]
----
public class CustomJsonLayout extends JsonLayout {
    @Override
    protected void addCustomDataToJsonMap(Map<String, Object> map, ILoggingEvent event) {
        map.put("application", "log-odissey");
        try {
            map.put("host", InetAddress.getLocalHost().getHostName());
        } catch (UnknownHostException e) {
        }
    }
}
----
Several Maven dependencies are required: `ch.qos.logback.contrib:logback-json-classic:0.1.5`, `ch.qos.logback.contrib:logback-jackson:0.1.5` and `com.fasterxml.jackson.core:jackson-databind`.
