= Testing Logstash configuration
:hp-tags: logstash
:published_at: 2016-09-07
:hp-image: images/logos/logstash.png

You wrote this piece of Logstash configuration which can parse some poorly formatted logs.
You tested several corner cases to ensure the output in Elasticsearch was alright.
How do you protect this complicated configuration file against regressions?

Unit testing to the rescue of course!

== Simple example

For the sake, of simplicity we will use an obvious example: access logs.
The input looks like

----
172.17.0.1 - - [05/Sep/2016:20:06:17 +0000] "GET /images/logos/hubpress.png HTTP/1.1" 200 5432 "http://localhost/" "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/51.0.2704.79 Chrome/51.0.2704.79 Safari/537.36" "-"
----

The output, once in Elasticsearch, should look like

[source,json]
----
{ "@version":"1",
  "@timestamp":"2016-09-05T20:06:17.000Z",
  "type":"nginx",
  "host":"XPS15-GQA", "path":"/var/log/nginx/access.log",
  "clientip":"172.17.0.1", "ident":"-", "auth":"-",
  "verb":"GET","request":"/images/logos/hubpress.png","httpversion":"1.1",
  "response":200, "bytes":5432, "referrer":"\"http://localhost/\"",
  "agent": "\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/51.0.2704.79 Chrome/51.0.2704.79 Safari/537.36\""
}
----

The configuration could look like

[source,ruby]
----
input {
    file {
        path => "/var/log/nginx/access*.log"
        type => "nginx"
    }
}
filter {
    if [type] == "nginx" {
        grok {
            match => [ "message" , "%{COMBINEDAPACHELOG}"]
        }
        date {
            match => [ "timestamp" , "dd/MMM/YYYY:HH:mm:ss Z" ]
        }
        mutate {
            convert => ["response", "integer"]
            convert => ["bytes", "integer"]
        }
    }
}
output {
    elasticsearch {
        codec => json_lines
    }
}
----

== Split the file

In the above config file, the interesting part, the one containing logic is the filter part.
In order to test it, the first thing to do is split this big file into small pieces:

- `01_logstash_input_nginx.conf` contains the nginx file input
- `02_logstash_filter_nginx.conf` contains the nginx filter section
- `03_logstash_output.conf` contains the elasticsearch output

In production, you can load multiple config files as if they were a single one:

----
logstash agent -f /etc/logstash.d/*.conf"
----

== Write the unit test

Now we aim at testing the `02_logstash_filter_nginx.conf` file.
We will use the JRuby unit testing framework called RSpec along with Logstash test utilities.

[source,ruby]
.02_logstash_filter_nginx_spec.rb
----
# encoding: utf-8
require "logstash/devutils/rspec/spec_helper"

file = "02_logstash_nginx_filter.conf"
@@configuration = String.new
@@configuration << File.read(file)

describe "Nginx filter" do

  config(@@configuration)

  message = "172.17.0.1 - - [05/Sep/2016:20:06:17 +0000] \"GET /images/logos/hubpress.png HTTP/1.1\" 200 5432 \"http://localhost/\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/51.0.2704.79 Chrome/51.0.2704.79 Safari/537.36\" \"-\""

  sample("message" => message, "type" => "nginx") do
    insist { subject["type"] } == "nginx"
    #insist { subject["@timestamp"] } == "2016-09-05T19:41:12.000Z"
    insist { subject["verb"] } == "GET"
    insist { subject["request"] } == "/images/logos/hubpress.png"
    insist { subject["response"] } == 200
    insist { subject["bytes"] } == 5432
  end
end
----


== Run the unit tests

Logstash comes with a `rspec` command to run this kind of code and provide the required dependencies.

----
$ logstash-2.4.0/bin/rspec 02_logstash_nginx_filter_spec.rb
Using Accessor#strict_set for specs
Run options: exclude {:redis=>true, :socket=>true, :performance=>true, :couchdb=>true, :elasticsearch=>true, :elasticsearch_secure=>true, :export_cypher=>true, :integration=>true, :windows=>true}
.

Finished in 0.115 seconds (files took 0.784 seconds to load)
1 example, 0 failures

Randomized with seed 4384
----


== To go further

You can find all the project source code
