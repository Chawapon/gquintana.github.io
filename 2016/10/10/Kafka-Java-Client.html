<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <title>Kafka Java Client</title>
    <meta name="description" content="" />

    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="shortcut icon" href="https://gquintana.github.io/favicon.ico">

    <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Merriweather:400,700,400italic,700italic|Open+Sans:400italic,700italic,700,400">
    <link rel="stylesheet" type="text/css" href="//gquintana.github.io/themes/roon/assets/css/screen.css?v=1476647511726" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/default.min.css" />

    <link rel="canonical" href="https://gquintana.github.io/2016/10/10/Kafka-Java-Client.html" />
    <meta name="referrer" content="origin" />
    
    <meta property="og:site_name" content="JRald" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Kafka Java Client" />
    <meta property="og:description" content="Apache Kafka is trendy software which mixes a message broker and an event log. From the ground up, it&amp;#8217;s a distributed solution designed for scalability and performance. It was created by LinkedIn in 2011, it is now open-source and supported by the Confluent company. For Java developers, until" />
    <meta property="og:url" content="https://gquintana.github.io/2016/10/10/Kafka-Java-Client.html" />
    <meta property="article:tag" content="kafka" />
    <meta property="article:tag" content=" java" />
    
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title" content="Kafka Java Client" />
    <meta name="twitter:description" content="Apache Kafka is trendy software which mixes a message broker and an event log. From the ground up, it&amp;#8217;s a distributed solution designed for scalability and performance. It was created by LinkedIn in 2011, it is now open-source and supported by the Confluent company. For Java developers, until" />
    <meta name="twitter:url" content="https://gquintana.github.io/2016/10/10/Kafka-Java-Client.html" />
    
    <script type="application/ld+json">
null
    </script>

    <meta name="generator" content="HubPress" />
    <link rel="alternate" type="application/rss+xml" title="JRald" href="https://gquintana.github.io/rss/" />
</head>
<body class="post-template tag-kafka tag-java  ">

    


    <article role="main" class="image">
        <header>
            <a href="https://gquintana.github.io" id="home_link">Â«</a>
            <div class="meta"><time datetime="2016-10-10"><a href="https://gquintana.github.io/2016/10/10/Kafka-Java-Client.html">October 10, 2016</a></time> <span class="count" id="js-reading-time"></span></div>
            <h1>
                    <img src="../../..//images/logos/kafka.png">
                Kafka Java Client
            </h1>
        </header>

        <div class="text" id="js-post-content">
            <div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>Apache Kafka is trendy software which mixes a message broker and an event log.
From the ground up, it&#8217;s a distributed solution designed for scalability and performance.
It was created by LinkedIn in 2011, it is now open-source and supported by the Confluent company.</p>
</div>
<div class="paragraph">
<p>For Java developers, until Kafka 0.8, there was only an intricate Scala API with Java bindings.
Since 0.9 there is a pure Java API which makes things simpler.
In this blog post we will discuss this API.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_creating_a_topic">Creating a Topic</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The <strong>topic</strong> is the place where messages are sent and where they are stored.
All messages send to Kafka are written to disk.</p>
</div>
<div class="paragraph">
<p>A topic is split into multiple <strong>partitions</strong>.
Each partition is usually placed on a different Kafka node.
Each partition can be <strong>replicated</strong> many times in order to tolerate node failures.
Among replicas, a leader is elected, it has the privilege of receiving messages first and sending messages to consumers.</p>
</div>
<div class="paragraph">
<p>A topic is automatically created when the first message arrives.
Alternatively, it may be manually created with the <code>kafka-topic.sh</code> command line tool:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ bin/kafka-topics.sh --zookeeper localhost:2181 --create --topic newtopic --partitions 5 --replication-factor 2
Created topic "newtopic".
$ bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic newtopic
Topic:newtopic  PartitionCount:5        ReplicationFactor:2     Configs:
        Topic: newtopic Partition: 0    Leader: 2       Replicas: 2,3   Isr: 2,3
        Topic: newtopic Partition: 1    Leader: 3       Replicas: 3,1   Isr: 3,1
        Topic: newtopic Partition: 2    Leader: 1       Replicas: 1,2   Isr: 1,2
        Topic: newtopic Partition: 3    Leader: 2       Replicas: 2,1   Isr: 2,1
        Topic: newtopic Partition: 4    Leader: 3       Replicas: 3,2   Isr: 3,2</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the above example, the topic has five partitions.
Partition 0 has two replicas: one on node 2, the other node 3.
The replica on node 2 is the leader.
You will notice the leader partitions are evenly distributed among this 3 node cluster.</p>
</div>
<div class="paragraph">
<p>Each partition is an independent log of events.
In this log, messages are <strong>sorted</strong> by their arrival order.
Each message is identified by its position in the log, this position is called <strong>offset</strong>.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://gquintana.github.io/images/2016-10-10-Kafka-Java-Client/kafka_topic.svg" alt="Topic" width="Partitions and Offsets">
</div>
</div>
<div class="paragraph">
<p>At the time of writing (Kafka 0.10.0), it is not possible to create or delete a Topic with the Kafka Client library.
By the way, this should change in the upcoming release (0.10.1).
Right now, you&#8217;ll have to stick with the forementioned command line tool, or use the Scala library which contains an <code>AdminUtils</code> class.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_message_record">Message / Record</h2>
<div class="sectionbody">
<div class="paragraph">
<p>A message is also called a <strong>record</strong> in the Kafka vocabulary.
It consists of:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>An optional <strong>key</strong>: it doesn&#8217;t guarantee message uniqueness, multiple messages may have the same key.</p>
</li>
<li>
<p>A <strong>value</strong>: the body, the main part of the message</p>
</li>
<li>
<p>A <strong>timestamp</strong> (since Kafka 0.10): when the message was created by the producer or recorded in the broker</p>
</li>
<li>
<p>An <strong>offset</strong>: a big number describing the position of the message in the log</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When the key is provided, it is hashed and this hash is used to determine in which partition it should go.
Two messages with the same key will end in the same partition.
Messages having the same key can be merged together by an optional background process called compaction.</p>
</div>
<div class="paragraph">
<p>The key and the value can be of any type: <code>String</code>, <code>long</code>, <code>byte[]</code>&#8230;&#8203;
This is made possible by <strong>serializers</strong> and <strong>deserializers</strong> which are strategies to read and write anything from byte stream.
Some (de)serializers are provided for basic types,
and there are some third party (de)serializers to handle complex types.
For example, it&#8217;s possible to exchange plain objects written in <a href="https://github.com/confluentinc/schema-registry/tree/master/json-serializer">JSON</a> or Avro format.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_sending_messages">Sending messages</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Messages are sent to the Kafka broker using a <strong>producer</strong>.
The producer knows the distribution of topic partitions on nodes,
it will hash the record key and send the record directly to the appropriate partition/node.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://gquintana.github.io/images/2016-10-10-Kafka-Java-Client/kafka_producer.svg" alt="Producer">
</div>
</div>
<div class="paragraph">
<p>When no key is provided, the producer uses a random partition.
In short, the producer is able to load balance writes to all partitions, and associated nodes.</p>
</div>
<div class="paragraph">
<p>This producer is initialized and configured with some properties.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">Map&lt;String, Object&gt; producerConfig = new HashMap&lt;&gt;();
producerConfig.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "kafka1:9092,kafka2:9092"); <i class="conum" data-value="1"></i><b>(1)</b>
producerConfig.put(ProducerConfig.ACKS_CONFIG, "1"); <i class="conum" data-value="5"></i><b>(5)</b>
producerConfig.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class); <i class="conum" data-value="4"></i><b>(4)</b>
producerConfig.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
try (Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(producerConfig)) {
    ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;&gt;("the_topic", "the_key","The Message"); <i class="conum" data-value="2"></i><b>(2)</b>
    Future&lt;RecordMetadata&gt; futureMetadata = producer.send(record);<i class="conum" data-value="3"></i><b>(3)</b>
    RecordMetadata metadata = producer.get(); <i class="conum" data-value="5"></i><b>(5)</b>
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Connect to these Kafka connect nodes.
The first Kafka node to answer will give the full list of nodes.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Create the record/message</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Send the message.
By default, this operation is asynchronous and non blocking, it immediately returns a <code>Future</code></td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>The message and the key are written on the wire using the string serializer.</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>Wait for message acknowledgement.
The <strong>Acks</strong> config indicates how many replicas should write the message to disk before returning an acknowledgement to the producer.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>In a real world application, the producer should be instanciated only once and reused for the application lifespan.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_receiving_messages">Receiving messages</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Messages are received from the Kafka broker by a <strong>consumer</strong>.
A consumer is a process in charge for reading messages from a topic and dealing with them.
As an acknowledgement, the consumer writes the message offset back to the broker, it&#8217;s called <strong>offset commit</strong>.</p>
</div>
<div class="paragraph">
<p>A <strong>consumer group</strong> is a set of consumers distributed on multiple machines.
For a given topic and group, each partition gets read by a single consumer.
This prevents messages from being consumed twice in the consumer group.
On the contrary, a consumer can be in charge of several partitions.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://gquintana.github.io/images/2016-10-10-Kafka-Java-Client/kafka_consumer.svg" alt="Consumer and Consumer Group">
</div>
</div>
<div class="paragraph">
<p>The Kafka cluster tells each consumer which partition it should read from.
Each consumer takes care of its portion of topic.
As a result, consumers can work independently and in parallel,
and messages stored in a topic can be load balanced to consumers on many machines.
In case of consumer failure, Kafka reassigns the partitions to other consumers of the same group.</p>
</div>
<div class="paragraph">
<p>Like the producer, the consumer is initialized and configured with some properties.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">Map&lt;String, Object&gt; consumerConfig = new HashMap&lt;&gt;();
consumerConfig.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "kafka1:9092,kafka2:9092"); <i class="conum" data-value="1"></i><b>(1)</b>
consumerConfig.put(ConsumerConfig.GROUP_ID_CONFIG, "test_group");
consumerConfig.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
consumerConfig.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
try (Consumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(consumerConfig)) {
    consumer.subscribe(Arrays.asList("the_topic")); <i class="conum" data-value="2"></i><b>(2)</b>
    ConsumerRecords&lt;String, String&gt; records = consumer.poll(1000L); <i class="conum" data-value="3"></i><b>(3)</b>
    for (ConsumerRecord&lt;String, String&gt; record : records) {
        LOGGER.info("Found message {} {}", record.key(), record.value());
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Connect to these Kafka connect nodes.
Like the producer, it doesn&#8217;t have to be the whole Kafka cluster.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Register this application (consumer group) as a consumer for this list of topics.
In return, Kafka will assign some partitions to this consumer.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Try to pull messages from the broker.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Pulled messages are automatically acknowledged.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>In the above example, connecting to the broker, subscribing to one or more topics,
and being assigned partitions takes time and is usually done once during application start-up.
On the contrary, the <code>poll</code> method should be run in loop.
It returns a batch of records whose size is controlled by the <code>max.poll.records</code> and <code>max.partition.fetch.bytes</code> settings.</p>
</div>
<div class="paragraph">
<p>Unlike the producer, the consumer is not thread-safe.
In order to consume records in parallel, each thread should have it&#8217;s own consumer.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_acknowledging_received_messages">Acknowledging received messages</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The message acknowledgement is called <strong>offset commit</strong>,
because Kafka keeps track of the offset of the last consumed message for each topic + partition + consumer group.</p>
</div>
<div class="paragraph">
<p>In the previous example, the offsets were automatically and periodically committed to the broker.
This auto commit is configurable through properties:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">consumerConfig.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true);
consumerConfig.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, 1000L);
try (Consumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(consumerConfig)) {
    consumer.subscribe(Arrays.asList("the_topic"));
    ConsumerRecords&lt;String, String&gt; records = consumer.poll(1000L);
    for (ConsumerRecord&lt;String, String&gt; record : records) {
        LOGGER.info("Found message {} {}", record.key(), record.value());
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>This offset commit can also be manual in order to ensure messages are acknowledged once they have been processed.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">consumerConfig.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);
try (Consumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(consumerConfig)) {
    consumer.subscribe(Arrays.asList("the_topic"));
    ConsumerRecords&lt;String, String&gt; records = consumer.poll(1000L);
    for (ConsumerRecord&lt;String, String&gt; record : records) {
        LOGGER.info("Found message {} {}", record.key(), record.value());
    }
    consumer.commitSync();
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>This offset can even be moved forward (to skip records) and backward (to replay records):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">    consumer.seekToBeginning(consumer.assignment());</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_using_a_framework">Using a framework</h2>
<div class="sectionbody">
<div class="paragraph">
<p>You may have noticed that the consumer API is a pull API.
In a real application you&#8217;ll have to create a consuming loop in separate thread,
and build a push API.</p>
</div>
<div class="paragraph">
<p>The <a href="http://docs.spring.io/spring-kafka/docs/current/reference/html/">Spring Kafka</a> does all the heavy lifting for you
and smoothly integrates Kafka with Spring and Spring Integration:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The <code>KafkaTemplate</code> can send messages</p>
</li>
<li>
<p>The <code>KafkaListener</code> can receive message in a push manner</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>This library makes Kafka usage very similar to ActiveMQ or RabbitMQ.</p>
</div>
</div>
</div>
        </div>

        <menu>
            <a href="" id="btn_share" class="btn" title="Share">
                <span aria-hidden="true" data-icon="S"></span>
                <strong>Share</strong>
            </a>
            <a href="http://twitter.com/share?text=Kafka%20Java%20Client&url=https://gquintana.github.io/2016/10/10/Kafka-Java-Client.html" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;" id="btn_comment" class="btn" target="_blank">
                <span aria-hidden="true" data-icon="C"></span> Comment on Twitter
            </a>
        </menu>


        <footer class="post-footer" role="contentinfo">

            <div class="vcard">
                <a href="https://gquintana.github.io/rss" id="btn_feed" class="btn" title="Feed" target="_blank">
                    <span aria-hidden="true" data-icon=")"></span>
                    <strong>Feed</strong>
                </a>

                <a href="https://gquintana.github.io/author/gquintana/" class="photo">
                    <span style="background-image: url('https://avatars.githubusercontent.com/u/755587?v&#x3D;3');">
                        <img src="https://avatars.githubusercontent.com/u/755587?v&#x3D;3" alt="Gerald Quintana">
                    </span>
                </a>

                <div class="details">
                    <h4><a href="https://gquintana.github.io/author/gquintana/" class="url n">Gerald Quintana</a></h4>
                    Lyon, France<br>
                    
                </div>
            </div>

            <div id="user_bio">
                <div class="inner">
                    
                </div>
            </div>

        </footer>




    </article>

    <div id="share_modal">
        <div class="wrap">
            <div class="inner">
                <header>
                    Share
                    <a href="" class="close" title="Close">&times;</a>
                </header>

                <div class="roon-share-links">
                    <a href="https://twitter.com/share" class="twitter-share-button" data-dnt="true">Tweet</a>
                    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src="//platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>

                    <div id="fb-elems">
                        <div id="fb-root"></div>
                        <script>(function(d, s, id) {
                        var js, fjs = d.getElementsByTagName(s)[0];
                        if (d.getElementById(id)) return;
                        js = d.createElement(s); js.id = id;
                        js.src = "//connect.facebook.net/en_US/all.js#xfbml=1&appId=463438580397968";
                        fjs.parentNode.insertBefore(js, fjs);
                        }(document, 'script', 'facebook-jssdk'));</script>
                        <div class="fb-like" data-send="false" data-layout="button_count" data-width="110" data-show-faces="false" data-font="arial"></div>
                    </div>

                    <div id="pinit-btn">
                        <a href="//pinterest.com/pin/create/button/?url=https://gquintana.github.io/2016/10/10/Kafka-Java-Client.html&amp;description=Kafka%20Java%20Client-JRald " data-pin-do="buttonPin" data-pin-config="beside"><img src="//assets.pinterest.com/images/pidgets/pin_it_button.png"></a>
                        <script type="text/javascript" src="//assets.pinterest.com/js/pinit.js"></script>
                    </div>
                </div>
            </div>
        </div>
    </div>






    <script>

            function get_text(el) {
                ret = "";
                var length = el.childNodes.length;
                for(var i = 0; i < length; i++) {
                    var node = el.childNodes[i];
                    if(node.nodeType != 8) {
                        ret += node.nodeType != 1 ? node.nodeValue : get_text(node);
                    }
                }
                return ret;
            }
            function reading_time () {
                var post_content = document.getElementById('js-post-content');
                if (post_content) {
                    var words = get_text(post_content),
                        count = words.split(/\s+/).length,
                        read_time = Math.ceil((count / 150)),
                        read_time_node = document.createTextNode(read_time + ' min read');
                    document.getElementById('js-reading-time').appendChild(read_time_node);
                }
            }

        function no_schema_links () {
            var links = document.querySelectorAll('.js-remove-domain-schema');
            if (links) {
                for (i = 0; i < links.length; ++i) {
                    var link = links[i],
                        text = link.innerHTML,
                        no_schema = text.replace(/.*?:\/\//g, "");
                    link.innerHTML = no_schema;
                }
            }
        }

        window.onload = function () {
            no_schema_links();

            reading_time();
        }
    </script>

    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js?v="></script> <script src="//cdnjs.cloudflare.com/ajax/libs/moment.js/2.9.0/moment-with-locales.min.js?v="></script> <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js?v="></script> 
      <script type="text/javascript">
        jQuery( document ).ready(function() {
          // change date with ago
          jQuery('ago.ago').each(function(){
            var element = jQuery(this).parent();
            element.html( moment(element.text()).fromNow());
          });
        });

        hljs.initHighlightingOnLoad();
      </script>

        <script>
            $(function(){
                var share_modal = $("#share_modal"),
                    update_social_links = true;

                $("#btn_share").click(function(){
                    var that = $(this);
                    share_modal.fadeIn(200);
                    return false;
                });

                share_modal.click(function(e){
                    if (e.target.className == "wrap" || e.target.id == "share_modal") {
                        share_modal.fadeOut(200);
                    }
                    return false;
                });

                share_modal.find("div.inner > header > a.close").click(function(){
                    share_modal.fadeOut(200);
                    return false;
                });
            });
        </script>


    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-85700184-1', 'auto');
    ga('send', 'pageview');

    </script>

</body>
</html>
